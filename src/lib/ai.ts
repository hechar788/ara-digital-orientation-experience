'use server'

import OpenAI, { APIError } from 'openai'
import type { Response as OpenAIResponse, ResponseCreateParamsNonStreaming } from 'openai/resources/responses/responses'
import { findPath, getRouteDescription, validatePath } from './pathfinding'

const LOCATION_IDS = [
  'a-f1-north-3-side',
  'a-f2-north-stairs-entrance',
  'n-f1-east-south-4',
  'n-f1-west-9',
  'n-f2-east-4',
  'n-f2-mid-3',
  's-f1-mid-3',
  's-f1-north-4',
  's-f1-south-2',
  's-f1-south-entrance',
  's-f2-mid-3',
  's-f2-mid-4',
  's-f2-south-5',
  's-f2-south-6',
  's-f2-south-7',
  's-f4-mid-4',
  's-f4-north-7',
  's-f4-north-8',
  'w-f2-4',
  'w-f2-5',
  'w-f2-6',
  'w-f2-7',
  'w-gym-overlook-1',
  'inside-student-lounge',
  'x-f1-east-4',
  'x-f1-mid-6-aside',
  'x-f1-mid-6-library',
  'x-f1-mid-7',
  'x-f1-mid-8',
  'x-f1-west-10',
  'x-f1-west-11',
  'x-f2-north-9-aside',
  'x-f2-west-2',
  'x-f2-west-3-aside',
  'x-f2-west-4',
  'x-f2-west-5-aside',
  'x-f2-west-6',
  'x-f3-east-6',
  'x-f3-east-8',
  'x-f3-west-1',
  'x-f3-west-1-aside'
] as const

const VALID_LOCATION_ID_SET = new Set<string>(LOCATION_IDS)

const LOCATION_KEYWORD_OVERRIDES = [
  {
    photoId: 'x-f1-east-4',
    keywords: ['coffee infusion', 'caf', 'cafe', 'café', 'coffee shop', 'coffee bar', 'coffee barista']
  },
  {
    photoId: 'inside-student-lounge',
    keywords: ['student lounge', 'student hub', 'student social space', 'student commons', 'student hangout']
  }
] as const satisfies Array<{
  photoId: (typeof LOCATION_IDS)[number]
  keywords: string[]
}>
let cachedClient: OpenAI | null = null
type GeneratedResponse = OpenAIResponse
type CreateResponseResult = Awaited<ReturnType<OpenAI['responses']['create']>>

function getOpenAIClient(): OpenAI {
  if (!cachedClient) {
    const apiKey = process.env.OPENAI_API_KEY

    if (!apiKey) {
      throw new Error('OPENAI_API_KEY is not set. Add it to your environment before using getChatResponse().')
    }

    cachedClient = new OpenAI({
      apiKey
    })
  }

  return cachedClient
}

function getVectorStoreId(): string {
  const vectorStoreId = process.env.OPENAI_LOCATIONS_VECTOR_STORE_ID

  if (!vectorStoreId) {
    throw new Error('OPENAI_LOCATIONS_VECTOR_STORE_ID is not set. Add it to your environment before using getChatResponse().')
  }

  return vectorStoreId
}

function isNonStreamingResponse(response: CreateResponseResult): response is GeneratedResponse {
  return typeof response === 'object' && response !== null && 'output' in response
}

function ensureNonStreamingResponse(response: CreateResponseResult): GeneratedResponse {
  if (isNonStreamingResponse(response)) {
    return response
  }
  throw new Error('OpenAI returned a streaming response; expected non-streaming output.')
}

/**
 * Describes a chat message exchanged with the AI assistant
 *
 * Used to pass prior conversation history back to the Responses API so the model
 * can reply with awareness of previous turns.
 *
 * @property role - Sender role for the message (`user`, `assistant`, or `system`)
 * @property content - Message body text provided to the model
 *
 * @example
 * ```typescript
 * const message: ChatMessage = { role: 'user', content: 'Where is the cafe?' }
 * ```
 */
export interface ChatMessage {
  role: 'user' | 'assistant' | 'system'
  content: string
}

/**
 * Represents a navigation function call generated by the AI assistant
 *
 * Extended in Phase 4 to bundle BFS pathfinding metadata so the client can
 * present step-by-step routes rather than teleporting directly to the
 * destination. Errors produced during path calculation are surfaced via the
 * optional `error` field so the UI can display friendly fallback messaging.
 *
 * @property name - Function identifier returned by the model (always `navigate_to`)
 * @property arguments - Navigation payload supplied with the function call
 * @property arguments.photoId - Destination campus photo identifier provided by the AI
 * @property arguments.path - Optional ordered list of photo IDs describing the computed route
 * @property arguments.distance - Optional number of steps contained in the route
 * @property arguments.routeDescription - Optional human-readable summary of the route
 * @property arguments.error - Optional explanation when path calculation fails
 *
 * @example
 * ```typescript
 * const functionCall: FunctionCall = {
 *   name: 'navigate_to',
 *   arguments: {
 *     photoId: 'library-f1-entrance',
 *     path: ['a-f1-north-entrance', 'a-f1-hallway', 'library-f1-entrance'],
 *     distance: 2,
 *     routeDescription: 'Route found: 2 steps from A Block F1 (North Entrance) to Library F1 Entrance.'
 *   }
 * }
 * ```
 */
export interface FunctionCall {
  name: 'navigate_to'
  arguments: {
    photoId: string
    path?: string[]
    distance?: number
    routeDescription?: string
    error?: string
  }
}

/**
 * Structured response returned from getChatResponse
 *
 * Used by the UI to differentiate between plain text replies, navigation tool
 * invocations, and recoverable errors.
 *
 * @property message - Assistant text reply or `null` when an error occurs
 * @property functionCall - Navigation command selected by the AI assistant
 * @property error - Present when the request fails for any reason
 *
 * @example
 * ```typescript
 * const response: ChatResponse = {
 *   message: 'Head through the atrium, then turn left toward the library entrance.',
 *   functionCall: {
 *     name: 'navigate_to',
 *     arguments: {
 *       photoId: 'library-f1-entrance',
 *       path: ['a-f1-north-entrance', 'a-f1-hallway', 'library-f1-entrance'],
 *       distance: 2,
 *       routeDescription: 'Route found: 2 steps from A Block F1 (North Entrance) to Library F1 Entrance.'
 *     }
 *   }
 * }
 * ```
 */
export interface ChatResponse {
  message: string | null
  functionCall: FunctionCall | null
  error?: string
}

/**
 * Maintains condensed chat history that survives across requests
 *
 * Tracks the rolling summary generated by the AI alongside the most recent
 * granular exchanges so future turns can reuse prior context without sending
 * the full transcript.
 *
 * @property summary - Condensed narrative of the conversation so far or `null` when no summary exists
 * @property messages - Recent verbatim chat messages preserved for precise follow-up handling
 *
 * @example
 * ```typescript
 * const state: ConversationState = {
 *   summary: 'Goal: Locate the library. Confirmed: navigation requested to x-f1-mid-6-library.',
 *   messages: [{ role: 'user', content: 'Can you take me to the library?' }]
 * }
 * ```
 */
export interface ConversationState {
  summary: string | null
  messages: ChatMessage[]
}

/**
 * Payload accepted by executeChatWithSummaries
 *
 * Carries the conversation memory from the client together with the next user
 * message and the viewer's current location identifier.
 *
 * @property state - Previously returned conversation state or `null` when the chat is new
 * @property nextMessage - Next chat turn to process, typically the latest user input
 * @property currentLocation - Viewer photo identifier describing the user's position
 *
 * @example
 * ```typescript
 * const input: ExecuteChatWithSummariesInput = {
 *   state: { summary: null, messages: [] },
 *   nextMessage: { role: 'user', content: 'Where is the cafeteria?' },
 *   currentLocation: 'a-f1-north-entrance'
 * }
 * ```
 */
export interface ExecuteChatWithSummariesInput {
  state: ConversationState | null
  nextMessage: ChatMessage
  currentLocation: string
}

/**
 * Result structure returned by executeChatWithSummaries
 *
 * Bundles the assistant response with the updated conversation memory that the
 * client should persist for the next request.
 *
 * @property response - Chat output including optional navigation tool call
 * @property state - Conversation state reflecting any new summaries and trimmed history
 *
 * @example
 * ```typescript
 * const result = await executeChatWithSummaries({
 *   state: { summary: null, messages: [] },
 *   nextMessage: { role: 'user', content: 'Take me to the gym' },
 *   currentLocation: 'a-f1-north-entrance'
 * })
 * console.log(result.state.summary)
 * // "Goal: Reach the gym. Confirmed navigation requested."
 * ```
 */
export interface ExecuteChatWithSummariesResult {
  response: ChatResponse
  state: ConversationState
}

const MAX_MESSAGE_COUNT = 20
const MAX_TOTAL_CHARACTERS = 5000
const SUMMARY_TRIGGER_THRESHOLD = 10
const SUMMARY_CHARACTER_THRESHOLD = 3500
const SUMMARY_TAIL_MESSAGE_COUNT = 6

const SUMMARISATION_SYSTEM_PROMPT = [
  'You compress campus navigation chats into a short memory summary.',
  'Capture the user’s goals, any confirmed destinations, and unresolved follow-ups.',
  'Keep the tone neutral and informative so it can be reused as context in future turns.',
  'Format the result as three concise bullet points prefixed with "Goals", "Confirmed", and "FollowUps".',
  'If information is unavailable for a bullet, write "None".',
  'Limit the entire summary to at most 120 words.',
  'Do not include filler phrases or explanations about the summarisation process.'
].join('\n')

const NAVIGATION_TOOL = {
  type: 'function' as const,
  name: 'navigate_to',
  description:
    'Automatically move the campus viewer to a specific location after the user confirms. Confirmations include phrases like "yes", "sure", or "please take me there". Use the photoId from the vector store record that matches the user request.',
  parameters: {
    type: 'object',
    properties: {
      photoId: {
        type: 'string',
        enum: LOCATION_IDS,
        description: 'Destination campus photo identifier'
      }
    },
    required: ['photoId'],
    additionalProperties: false
  },
  strict: true
}

const AFFIRMATION_REMINDER = [
  '- Only call the navigate_to tool when the user confirms they want navigation',
  '- Use the vector store results to double-check that the destination exists before navigating',
  '- Do not call navigate_to if the user merely asks for information without confirming',
  '- When a user explicitly provides a photoId (for example, photoId: "x-f1-east-4"), call navigate_to with that exact identifier as long as it appears in the allowlist',
  '- When you identify the correct record in the vector store, use that document’s id as the navigate_to photoId. Do not substitute a different allowlisted id',
  '- Example: For Coffee Infusion, call navigate_to with photoId: "x-f1-east-4" once the user confirms'
].join('\n')

const EXAMPLE_CONVERSATIONS = [
  'User: "Where is the library?"',
  'You: "The Library is southwest from the main entrance. From A Block, follow the corridor and turn left at the atrium.\nWould you like me to take you there?"',
  '',
  'User: "yes please"',
  'You: [Call navigate_to function with photoId: "x-f1-mid-6-library"]',
  '',
  'User: "I can\'t find the cafe."',
  'You: "The café, Coffee Infusion, is inside X Block on the first floor.\nWould you like me to take you there?"',
  '',
  'User: "yes please"',
  'You: [Call navigate_to function with photoId: "x-f1-east-4"]',
  '',
  'User: "hi"',
  'You: "Hello! I can help you find locations around Ara Institute. What would you like to find?"',
  '',
  'User: "I need the Student Finance office."',
  'You: "Student Finance is inside X Block near Careers & Employment. From your current location, head toward the western wing.\nWould you like me to take you there?"',
  '',
  'User: "Can you help me with fitness tips?"',
  'You: "I’m here to help with campus locations and navigation. Ask me about a building, room, or facility you would like to visit."',
  '',
  'User: "No thanks"',
  'You: "No problem! Let me know if you need directions to another location around campus."'
].join('\n')

function buildSystemPrompt(currentLocation: string): string {
  return [
    'You are a helpful campus navigation assistant at Ara Institute of Canterbury.',
    '',
    `Current user location: ${currentLocation}`,
    '',
    'Knowledge source:',
    'Use the "locations" vector store via the file_search tool to interpret destinations, synonyms, and building context. If you cannot find a match, apologise and explain that the location is not yet available.',
    '- When you cite a vector store result, use that document’s `id` as the photoId if the user confirms navigation.',
    '',
    'Your role:',
    '1. Provide concise, friendly directions from the current location.',
    '2. Ask whether the user would like automatic navigation.',
    '3. Only when the user confirms with an affirmative phrase, call the navigate_to tool.',
    '',
    'Conversation style:',
    '- Be approachable and clear.',
    '- Keep responses focused and free of filler.',
    '- Handle greetings naturally.',
    '- Apologise when a destination is unavailable.',
    '- Users cannot upload files. Never mention uploads, attachments, or documents under any circumstance.',
    '- Stay on topic. For requests unrelated to campus navigation, politely redirect the user to ask about locations instead of providing off-topic guidance.',
    '',
    'Example conversations:',
    EXAMPLE_CONVERSATIONS,
    '',
    'Important reminders:',
    AFFIRMATION_REMINDER
  ].join('\n')
}

function parseResponseText(output: GeneratedResponse['output']): string | null {
  const parts: string[] = []
  for (const item of output ?? []) {
    if (item.type === 'message' && Array.isArray(item.content)) {
      for (const contentPart of item.content) {
        if (contentPart.type === 'output_text' && contentPart.text) {
          parts.push(contentPart.text)
        }
      }
    }
  }
  const combined = parts.join('').trim()
  return combined.length > 0 ? combined : null
}

function parseFunctionCall(output: GeneratedResponse['output']): FunctionCall | null {
  for (const item of output ?? []) {
    if (item.type === 'function_call' && item.name === 'navigate_to') {
      try {
        const parsedArguments = JSON.parse(item.arguments ?? '{}')
        const photoId = typeof parsedArguments.photoId === 'string' ? parsedArguments.photoId : undefined
        if (photoId && VALID_LOCATION_ID_SET.has(photoId)) {
          return {
            name: 'navigate_to',
            arguments: { photoId }
          }
        }
      } catch (error) {
        console.error('[AI] Failed to parse function call arguments', error)
      }
    }
  }
  return null
}

function normaliseMessageInput(messages: ChatMessage[]) {
  return messages.map(message => ({
    role: message.role,
    content: message.content,
    type: 'message' as const
  }))
}

function findOverrideFromText(text: string | null): string | null {
  if (!text) {
    return null
  }
  const normalised = text.toLowerCase()
  for (const mapping of LOCATION_KEYWORD_OVERRIDES) {
    if (mapping.keywords.some(keyword => normalised.includes(keyword))) {
      return mapping.photoId
    }
  }
  return null
}

function findLatestUserMessage(messages: ChatMessage[]): string | null {
  for (let index = messages.length - 1; index >= 0; index--) {
    const message = messages[index]
    if (message.role === 'user') {
      return message.content
    }
  }
  return null
}

function applyKeywordOverrides(
  originalCall: FunctionCall | null,
  assistantMessage: string | null,
  messages: ChatMessage[]
): FunctionCall | null {
  if (!originalCall) {
    return null
  }
  const sources: Array<string | null> = [assistantMessage, findLatestUserMessage(messages)]
  for (const source of sources) {
    const overridePhotoId = findOverrideFromText(source)
    if (overridePhotoId && overridePhotoId !== originalCall.arguments.photoId && VALID_LOCATION_ID_SET.has(overridePhotoId)) {
      return {
        name: 'navigate_to',
        arguments: {
          photoId: overridePhotoId
        }
      }
    }
  }
  return originalCall
}

function augmentFunctionCallWithPath(
  originalCall: FunctionCall | null,
  currentLocation: string
): FunctionCall | null {
  if (!originalCall) {
    return null
  }

  if (originalCall.arguments.error) {
    return originalCall
  }

  if (!currentLocation) {
    return {
      name: originalCall.name,
      arguments: {
        photoId: originalCall.arguments.photoId,
        error: 'Current location is unavailable for pathfinding.'
      }
    }
  }

  const destinationId = originalCall.arguments.photoId
  const pathResult = findPath(currentLocation, destinationId)

  if (!pathResult) {
    return {
      name: originalCall.name,
      arguments: {
        photoId: destinationId,
        error: 'Unable to calculate a route from the current location to the requested destination.'
      }
    }
  }

  if (!validatePath(pathResult)) {
    return {
      name: originalCall.name,
      arguments: {
        photoId: destinationId,
        error: 'Calculated route failed validation. Please try again.'
      }
    }
  }

  const routeDescription = getRouteDescription(pathResult)

  return {
    name: originalCall.name,
    arguments: {
      photoId: destinationId,
      path: pathResult.path,
      distance: pathResult.distance,
      routeDescription
    }
  }
}

function getTotalCharacterCount(messages: ChatMessage[]): number {
  return messages.reduce((total, message) => total + message.content.length, 0)
}

function validateMessages(messages: ChatMessage[]): string | null {
  if (!messages || messages.length === 0) {
    return 'No messages provided.'
  }
  if (messages.length > MAX_MESSAGE_COUNT) {
    return 'Conversation too long. Please start a new chat.'
  }
  const totalCharacters = getTotalCharacterCount(messages)
  if (totalCharacters > MAX_TOTAL_CHARACTERS) {
    return 'Message too long. Please be more concise.'
  }
  return null
}

function shouldSummariseConversation(messageCount: number, totalCharacters: number): boolean {
  return messageCount >= SUMMARY_TRIGGER_THRESHOLD || totalCharacters >= SUMMARY_CHARACTER_THRESHOLD
}

function buildMessagesForRequest(summary: string | null, messages: ChatMessage[]): ChatMessage[] {
  const trimmedSummary = summary?.trim()
  if (trimmedSummary) {
    return [
      {
        role: 'system',
        content: `Conversation summary: ${trimmedSummary}`
      },
      ...messages
    ]
  }
  return messages
}

type SummariseConversationInput = {
  priorSummary: string | null
  messages: ChatMessage[]
}

type SummariseConversationResult = {
  summary: string | null
  updated: boolean
}

async function summariseConversation({
  priorSummary,
  messages
}: SummariseConversationInput): Promise<SummariseConversationResult> {
  if (!messages.length) {
    return {
      summary: priorSummary ?? null,
      updated: false
    }
  }

  try {
    const client = getOpenAIClient()
    const rawResponse = await client.responses.create({
      model: 'gpt-4o-mini',
      input: [
        {
          role: 'system',
          content: SUMMARISATION_SYSTEM_PROMPT,
          type: 'message'
        },
        ...(priorSummary
          ? [
              {
                role: 'system' as const,
                content: `Previous summary:\n${priorSummary}`,
                type: 'message' as const
              }
            ]
          : []),
        ...normaliseMessageInput(messages)
      ],
      temperature: 0.2,
      max_output_tokens: 200
    } satisfies ResponseCreateParamsNonStreaming)
    const response = ensureNonStreamingResponse(rawResponse)

    const summary = response.output_text?.trim() ?? parseResponseText(response.output) ?? null
    if (summary && summary.length > 0) {
      console.info('[AI] Conversation summary generated', {
        hadPriorSummary: !!priorSummary,
        summarisedMessageCount: messages.length,
        summaryLength: summary.length
      })
      return {
        summary,
        updated: summary !== (priorSummary ?? null)
      }
    }
  } catch (error) {
    console.error('[AI] Failed to summarise conversation', error)
  }
  return {
    summary: priorSummary ?? null,
    updated: false
  }
}

function handleKnownApiErrors(error: unknown): ChatResponse | null {
  if (error instanceof APIError) {
    if (error.status === 429) {
      return {
        message: null,
        functionCall: null,
        error: 'The AI is responding to many requests right now. Please try again shortly.'
      }
    }
    if (error.status === 401) {
      return {
        message: null,
        functionCall: null,
        error: 'AI service configuration error. Check your API credentials.'
      }
    }
    if (typeof error.status === 'number' && error.status >= 500) {
      return {
        message: null,
        functionCall: null,
        error: 'The AI service is temporarily unavailable. Please try again.'
      }
    }
  }
  if (
    typeof error === 'object' &&
    error !== null &&
    'code' in error &&
    (error as { code?: string }).code &&
    ['ECONNREFUSED', 'ETIMEDOUT'].includes((error as { code: string }).code)
  ) {
    return {
      message: null,
      functionCall: null,
      error: 'Network error while contacting the AI service. Please check your connection.'
    }
  }
  return null
}

interface ExecuteChatInput {
  messages: ChatMessage[]
  currentLocation: string
}

/**
 * Generates an OpenAI navigation response using the supplied chat history
 *
 * Validates the message payload, assembles the navigation system prompt, and
 * invokes the Responses API so the assistant can reply with directions or
 * trigger the navigation tool call.
 *
 * @param input - Request details for the current turn
 * @param input.messages - Chat history supplied to the model in chronological order
 * @param input.currentLocation - Viewer photo identifier describing the user’s current position
 * @returns ChatResponse containing an assistant message, optional tool call, or an error description
 *
 * @example
 * ```typescript
 * const response = await executeChat({
 *   messages: [{ role: 'user', content: 'Where is the student lounge?' }],
 *   currentLocation: 'a-f1-north-entrance'
 * })
 * ```
 */
export async function executeChat({ messages, currentLocation }: ExecuteChatInput): Promise<ChatResponse> {
  console.info('[AI] getChatResponse invoked', {
    messageCount: messages?.length ?? 0,
    currentLocation
  })

  if (!currentLocation) {
    return {
      message: null,
      functionCall: null,
      error: 'Current location is required for navigation.'
    }
  }

  const validationError = validateMessages(messages)
  if (validationError) {
    return {
      message: null,
      functionCall: null,
      error: validationError
    }
  }

  try {
    const client = getOpenAIClient()
    const vectorStoreId = getVectorStoreId()

    console.info('[AI] Preparing OpenAI request', {
      vectorStoreId,
      messageCount: messages.length
    })

    const rawResponse = await client.responses.create({
      model: 'gpt-4o-mini',
      input: [
        {
          role: 'system',
          content: buildSystemPrompt(currentLocation),
          type: 'message'
        },
        ...normaliseMessageInput(messages)
      ],
      tools: [
        {
          type: 'file_search',
          vector_store_ids: [vectorStoreId]
        },
        NAVIGATION_TOOL
      ],
      temperature: 0.2,
      max_output_tokens: 200
    } satisfies ResponseCreateParamsNonStreaming)
    const response = ensureNonStreamingResponse(rawResponse)

    const message =
      response.output_text?.trim() ??
      parseResponseText(response.output) ??
      null
    const functionCall = parseFunctionCall(response.output)

    const adjustedFunctionCall = applyKeywordOverrides(functionCall, message, messages)
    const pathAwareFunctionCall = augmentFunctionCallWithPath(adjustedFunctionCall, currentLocation)

    console.info('[AI] OpenAI response summary', {
      hasMessage: !!message,
      hasFunctionCall: !!pathAwareFunctionCall,
      pathStepCount: pathAwareFunctionCall?.arguments.path?.length ?? 0,
      pathError: pathAwareFunctionCall?.arguments.error ?? null
    })

    return {
      message,
      functionCall: pathAwareFunctionCall
    }
  } catch (error) {
    console.error('[AI] Response generation failed', error)
    const handled = handleKnownApiErrors(error)
    if (handled) {
      return handled
    }
    return {
      message: null,
      functionCall: null,
      error: 'Sorry, something went wrong while contacting the AI service.'
    }
  }
}

/**
 * Generates an AI response while maintaining a rolling conversation summary
 *
 * Automatically compacts older chat turns into a structured summary when the
 * history approaches model limits, ensuring users can continue longer sessions
 * without encountering hard reset errors.
 *
 * @param input - Payload containing the previous state and the next message
 * @param input.state - Previously persisted conversation memory or `null` for new chats
 * @param input.nextMessage - Latest chat message to process
 * @param input.currentLocation - Viewer photo identifier representing the user’s position
 * @returns ExecuteChatWithSummariesResult containing the assistant reply and updated memory state
 *
 * @example
 * ```typescript
 * const result = await executeChatWithSummaries({
 *   state: { summary: null, messages: [] },
 *   nextMessage: { role: 'user', content: 'Where is the library?' },
 *   currentLocation: 'a-f1-north-entrance'
 * })
 * console.log(result.response.message)
 * ```
 */
export async function executeChatWithSummaries({
  state,
  nextMessage,
  currentLocation
}: ExecuteChatWithSummariesInput): Promise<ExecuteChatWithSummariesResult> {
  const baseState: ConversationState = {
    summary: state?.summary ?? null,
    messages: Array.isArray(state?.messages) ? state.messages : []
  }

  const normalisedNextMessage: ChatMessage = {
    role: nextMessage.role,
    content: nextMessage.content.trim()
  }

  if (!normalisedNextMessage.content) {
    return {
      response: {
        message: null,
        functionCall: null,
        error: 'Message cannot be empty.'
      },
      state: baseState
    }
  }

  const combinedMessages = [...baseState.messages, normalisedNextMessage]
  const totalCharacters = getTotalCharacterCount(combinedMessages)

  let workingSummary = baseState.summary
  let workingMessages = combinedMessages

  const needsSummarisation =
    shouldSummariseConversation(combinedMessages.length, totalCharacters) &&
    combinedMessages.length > SUMMARY_TAIL_MESSAGE_COUNT

  if (needsSummarisation) {
    const sliceIndex = Math.max(combinedMessages.length - SUMMARY_TAIL_MESSAGE_COUNT, 0)
    const messagesToSummarise = combinedMessages.slice(0, sliceIndex)
    const messagesToKeep = combinedMessages.slice(sliceIndex)

    if (messagesToSummarise.length > 0) {
      const summaryResult = await summariseConversation({
        priorSummary: baseState.summary,
        messages: messagesToSummarise
      })

      if (summaryResult.summary) {
        workingSummary = summaryResult.summary
      }

      if (summaryResult.updated && summaryResult.summary) {
        workingMessages = messagesToKeep
        console.info('[AI] Rolled conversation into summary', {
          retainedMessages: workingMessages.length,
          summarisedCount: messagesToSummarise.length
        })
      } else if (combinedMessages.length > MAX_MESSAGE_COUNT) {
        workingMessages = combinedMessages.slice(-MAX_MESSAGE_COUNT)
        console.warn('[AI] Summary unchanged; trimming conversation to last turns', {
          retainedMessages: workingMessages.length
        })
      }
    }
  } else if (combinedMessages.length > MAX_MESSAGE_COUNT) {
    workingMessages = combinedMessages.slice(-MAX_MESSAGE_COUNT)
  }

  let messagesForRequest = buildMessagesForRequest(workingSummary, workingMessages)

  if (messagesForRequest.length > MAX_MESSAGE_COUNT) {
    const systemMessages = messagesForRequest.filter(message => message.role === 'system')
    const nonSystemMessages = messagesForRequest.filter(message => message.role !== 'system')
    const keptSystemMessages = systemMessages.slice(-1)
    const allowedNonSystemCount = Math.max(MAX_MESSAGE_COUNT - keptSystemMessages.length, 0)
    messagesForRequest = [
      ...keptSystemMessages,
      ...nonSystemMessages.slice(-allowedNonSystemCount)
    ]
  }

  const response = await executeChat({
    messages: messagesForRequest,
    currentLocation
  })

  const assistantContent =
    response.message ??
    response.functionCall?.arguments.routeDescription ??
    (response.functionCall ? `Navigation command issued for ${response.functionCall.arguments.photoId}.` : null)

  let nextStateMessages = workingMessages

  if (assistantContent) {
    nextStateMessages = [
      ...nextStateMessages,
      {
        role: 'assistant',
        content: assistantContent.trim()
      }
    ]
  }

  if (nextStateMessages.length > MAX_MESSAGE_COUNT) {
    nextStateMessages = nextStateMessages.slice(-MAX_MESSAGE_COUNT)
  }

  return {
    response,
    state: {
      summary: workingSummary,
      messages: nextStateMessages
    }
  }
}
